apply plugin: 'scala'

dependencies {
  compile "org.apache.spark:spark-core_2.10:${sparkVersion}"
  compile "org.apache.spark:spark-streaming_2.10:${sparkVersion}"
  compile "org.apache.spark:spark-graphx_2.10:${sparkVersion}"
  compile "io.argonaut:argonaut_2.10:6.1"
  testCompile "org.scalatest:scalatest_2.10:2.2.6"
  runtime "org.slf4j:slf4j-log4j12:${slf4jVersion}"
}

configurations.all {
  exclude module: 'logback-classic'
}

//task stream(type:JavaExec) {
//  main = 'tutorial.mr.task3.streaming.Stream'
//  classpath = sourceSets.main.runtimeClasspath
//  /* Can pass all the properties: */
//  systemProperties System.getProperties()
//  
//  /* Need to split the space-delimited value in the exec.args */
//  if ( System.getProperty("exec.args") )
//    args System.getProperty("exec.args").split()
//}

test {
  systemProperties = [
    "hadoop.home.dir": "${System.getProperty('user.dir')}"
  ]
}

processTestResources.dependsOn  downloadBooks
